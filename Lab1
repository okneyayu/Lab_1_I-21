import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords, twitter_samples
from nltk.tokenize import TweetTokenizer
from nltk.stem import PorterStemmer
import re
import string

# Завантаження необхідних даних
nltk.download('twitter_samples')
nltk.download('stopwords')

# Функція для попередньої обробки текстів
def process_tweet(tweet):
    stemmer = PorterStemmer()
    stopwords_english = stopwords.words('english')
    tweet = re.sub(r'\$\w*', '', tweet)
    tweet = re.sub(r'^RT[\s]+', '', tweet)
    tweet = re.sub(r'https?://[\S]+', '', tweet)
    tweet = re.sub(r'#', '', tweet)
    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)
    tweet_tokens = tokenizer.tokenize(tweet)

    tweets_clean = []
    for word in tweet_tokens:
        if word not in stopwords_english and word not in string.punctuation:
            stem_word = stemmer.stem(word)
            tweets_clean.append(stem_word)

    return tweets_clean

# Побудова словника частотності слів
def build_freqs(tweets, ys):
    yslist = np.squeeze(ys).tolist()
    freqs = {}
    for y, tweet in zip(yslist, tweets):
        for word in process_tweet(tweet):
            pair = (word, y)
            if pair in freqs:
                freqs[pair] += 1
            else:
                freqs[pair] = 1
    return freqs

# Функція сигмоїди
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Градієнтний спуск
def gradientDescent(x, y, theta, alpha, num_iters):
    m = x.shape[0]
    for i in range(num_iters):
        z = np.dot(x, theta)
        h = sigmoid(z)
        J = (-1 / m) * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))
        theta -= (alpha / m) * np.dot(x.T, (h - y))
    return J, theta

# Вилучення ознак
def extract_features(tweet, freqs):
    word_l = process_tweet(tweet)
    x = np.zeros((1, 3))
    x[0, 0] = 1  # bias
    for word in word_l:
        if (word, 1.0) in freqs:
            x[0, 1] += freqs[(word, 1.0)]
        if (word, 0.0) in freqs:
            x[0, 2] += freqs[(word, 0.0)]
    return x

# Передбачення

def predict_tweet(tweet, freqs, theta):
    x = extract_features(tweet, freqs)
    y_pred = sigmoid(np.dot(x, theta))
    return y_pred

# Завантаження даних
pos_tweets = twitter_samples.strings('positive_tweets.json')
neg_tweets = twitter_samples.strings('negative_tweets.json')

train_pos = pos_tweets[:4000]
train_neg = neg_tweets[:4000]
test_pos = pos_tweets[4000:]
test_neg = neg_tweets[4000:]

train_x = train_pos + train_neg
test_x = test_pos + test_neg

train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)
test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)

# Обробка тренувальних даних
freqs = build_freqs(train_x, train_y)
X = np.zeros((len(train_x), 3))
for i in range(len(train_x)):
    X[i, :] = extract_features(train_x[i], freqs)

Y = train_y

# Навчання моделі
alpha = 1e-9
num_iters = 1500
J, theta = gradientDescent(X, Y, np.zeros((3, 1)), alpha, num_iters)

# Тестування моделі
def test_logistic_regression(test_x, test_y, freqs, theta):
    y_hat = []
    for tweet in test_x:
        y_pred = predict_tweet(tweet, freqs, theta)
        y_hat.append(1 if y_pred > 0.5 else 0)
    accuracy = (np.sum(np.array(y_hat) == np.squeeze(test_y))) / len(test_y)
    return accuracy

accuracy = test_logistic_regression(test_x, test_y, freqs, theta)
print(f"Точність моделі: {accuracy:.4f}")

# Перевірка на власних прикладах
my_tweet = "I love this product! It works perfectly."
y_hat = predict_tweet(my_tweet, freqs, theta)
print("Позитивна" if y_hat > 0.5 else "Негативна")
